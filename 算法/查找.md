### 0x00 查找

主要有如下查找算法（Searching Algorithms)：

* 顺序查找（Linear Search）
* 二分查找（又称折半查找Binary Search）

以及几个对查找优化的数据类型：

* 哈希表（又称散列表Hash Table）
* B树（参见树那一节）

介绍一个基本概念叫做平均查找长度（ASL）：

ASL的计算公式如下：
$$
ASL=\sum_{i=1}^n P_i\times C_i
$$

> 上式中
>
> * n为查找长度
> * $P_i$为第$i$个元素为目标的概率
> * $C_i$为找到第$i$个元素所需要进行的比较次数

### 0x01 顺序查找和二分查找

#### 0x00 顺序查找

顺序查找不做详述，就是最简单的查找算法，从第一个开始往后依次查找，直到找到目标或者到达结尾。顺序表一般针对**无序的序列**。

在此，不给出代码了，仅分析其平均查找长度，对于顺序查找而言在查找成功的情况下，ASL计算为：
$$
ASL=\sum_{i=1}^n \frac{i}{n} = \frac{n+1}{2}
$$
其中，认为每个元素的查找概率均相同均为$\frac{1}{n}$，当定位目标元素为第$i$个元素时，需进行$i$次比较。

如果查找不成功的话，表中所有的元素都要被比较一次，而且最后还多了一次输入是否到头的比较过程，比较次数即为$n+1$，平均查找长度即为$ASL=n+1$。

顺序查找对表没有任何的要求，可以是顺序表也可是链表，可以有序也可以无序。但是当N较大时，平均查找较长，效率较低。同时对线性的链表只能进行顺序查找。

还要单独说一下有序表的顺序查找，如果在查找之前就知道输入序列有序的话，例如如下输入序列：

```
1 2 4 5 6 7 8 9
```

当我要查找元素3时，当查找到第一个比3大的元素时还没有找到3，算法就可以终止了，在此处，当比较到4时，就没必要再继续下去了。这样可以进一步地优化一下查找失败时的平均查找长度：
$$
ASL_{查找失败时}=\frac{1+2+3+...+n+n}{n+1}=\frac{n}{2}+\frac{n}{n+1}
$$
反正也查不到，那平均到每一次到达失败结点的概率即为$\frac{1}{n+1}$，此处n+1的原因是有n+1个查找失败的顶点，因为我把整个表全部扫描了一遍，我最后还多了一次判断输入是否到头的比较过程。分子最后多了个+n的原因是，当查找进行到输入数据末尾时，由于每一次查找都多了一次比较当前元素是否小于被查找元素的过程，有n个元素，自然也多了n次比较小于的过程。

#### 0x01 二分查找

二分查找又称折半查找，一般用于有序的顺序表。

先从一道LeetCode题目说起，[704. Binary Search](https://leetcode.com/problems/binary-search/description/)，这是一道简单题，目的很单纯，就是给你一个顺序表，然后给你一个待查找的元素，让你使用二分查找的方法来查找元素在顺序表中的位置，代码如下：

```c++
class Solution {
public:
    int search(std::vector<int>& nums, int target) {
        int lo = 0, hi = nums.size(), mid;
        while (lo < hi)
        {
            mid = (lo + hi) >> 1;
            if (nums[mid] == target)
            {
                return mid;
            }
            else if(nums[mid] > target)
            {
                hi = mid;
            }
            else
            {
                lo = mid + 1;
            }
        }
        return -1;
    }
};
```

二分查找的过程可以用一棵二叉树来描述，这棵二叉树也被称为判定树，

对于一个待查找的输入数列：

```
1 2 3 4 5 6 7 8 9 10 11 12
```

我们可以画出其二分查找时的判定树，如下图：

![](https://bucket.shaoqunliu.cn/image/0186.png)

下面来分析一下二分查找的平均查找长度：

由上图可以看出，使用二分查找查找到给定值的时间复杂度不会超过其判定树的高度，所以有：
$$
ASL=\sum_{i=1}^h{\frac{1}{n}\times (i\times2^{i-1})} \\
ASL=\frac{1}{n} \times (1\times1+2\times2+...+h\times2^{h-1})\\
ASL=\frac{n+1}{n}\log_2{(n+1)}-1 \\
\Rightarrow ASL\approx \log_2{(n+1)}-1
$$

在上式中，h为判定树的高度，当有N个结点时，判定树的高度为：

$$
h=\lceil \log_2{(N+1)} \rceil
$$

由此可知，二分查找的时间复杂度为$O(\log_2{N})$。

二分查找有一个特点就是需要方便地定位到数列中间的那个位置，所以适合用二分查找的存储结构要具有随机访问的特性，例如数组。因此其并不适用于链表等链式存储结构。

#### 0x02 分块查找

分块查找又称索引顺序查找，可以看为是二分查找和顺序查找的一个整合版本，其基本思想是：

* 将查找表分为若干块，块内的元素可以是无序的，但是块与块之间是有序的，例如第一个块中的最大关键字小于第二个块中的最小关键字，以此类推。
* 有一个索引表，索引表包含了每个块含有的最大关键字，以及第一个起始元素的位置，索引表按关键字有序排列。

分块查找的查找过程分两步，第一步在索引表中确定待查记录所在的块，可以使用顺序查找或折半查找，然后第二步在块内顺序查找。

将索引查找的平均查找长度记为$L_I$，块内查找的平均查找长度记为$L_S$，则ASL有如下计算：
$$
ASL=L_I+L_S\\
$$
设将长度为n的表平均分为了b块，每块有s条记录，若对索引表使用二分查找时，平均查找长度为：
$$
ASL=\lceil \log_2{(b+1)} \rceil+\frac{s+1}{2}
$$
若对索引表也使用顺序查找，则平均查找长度为：
$$
ASL=\frac{b+1}{2}+\frac{s+1}{2}\\
代入b=\frac{n}{s}有:ASL=\frac{n+s}{2s}+\frac{s+1}{2}\\
\Rightarrow ASL=\frac{s^2+2s+n}{2s}
$$

### 0x02 哈希表

#### 0x00 基本概念

哈希表（Hash table）又叫散列表，往往被用来实现关联数组（Associative array）。同样可以用来进行快速地查找，其具有以下几个基本概念：

* 散列函数（Hash function）：用于把查找表中的关键字映射成该关键字对应地址的函数，国内教材上一般记为：

  ```c++
  addr = Hash(key); // 通过散列函数Hash得到关键字key的地址Addr
  ```

  国外教材上一般写为如下两种形式：

  ```c++
  // 通过散列函数f得到关键字key的地址index
  // 其中散列函数需传入查找表数组的大小array_size
  index = f(key, array_size); 
  ```

  或者：

  ```c++
  // 通过散列函数hashfunc得到关键字key所对应的地址hash
  hash = hashfunc(key);
  // 通过这个地址hash与查找表数组大小进行模运算以获取其在查找表的索引地址
  index = hash % array_size;
  ```

* 散列表：根据关键字直接访问的数据结构，其建立了关键字和存储地址之间的一种直接映射关系

在理想情况下，对Hash表进行查找的时间复杂度为$O(1)$

再介绍一个概念叫做装填因子（load factor），其计算公式如下：
$$
\text{load factor}=\frac{\text{size}}{\text{capacity}}
$$
其中，size为哈希表中实际存储的有效元素的个数，capacity为哈希表的容量。

#### 0x01 散列函数的构造

构造散列函数时，必需注意如下几点：

* **散列函数的定义域必需包含全部需要存储的关键字，而值域的范围则依赖于散列表的大小或地址范围**
* **散列函数计算出来的地址应该能等概率地、离散地、均匀地分布在整个地址空间（discrete uniform distribution）**，从而减少冲突的发生
* 散列函数应尽量简单，在较短的时间复杂度内算出任一关键字所对应的散列地址

下面介绍集中常用的散列函数：

##### 0x00 直接定址法

就是使用线性函数来计算散列地址：

```c++
AddressIndex hashFunc(ElemType key) {
    return a*key + b; // 此处的a和b为常数
}
```

这种方法快且简单，而且不会产生冲突，**仅适合于关键字的分布基本连续的情况**，若关键字分布不连续空位较多，那么将会导致大量存储空间的浪费。

##### 0x01 除留余数法

```c++
AddressIndex hashFunc(ElemType key) {
    return key % p; // 其中p为质数
}
```

这同样是一种简单而实用的办法，假定散列表的长度为m，则**取小于等于m的最大质数作为p**，然后通过取余运算以计算其散列地址。此方法的关键在于质数p的选择，选择一个好的质数p，可以使得每一个关键字都等概率地映射到空间上的任意地址，减少冲突的可能。

##### 0x02 平方取中法

就是取关键字平方值的中间几位作为散列地址。具体取多少位要依实际情况而定，这种方法得到的散列地址与关键字的每一位都有关系，使得散列值分布地比较均匀。**适用于关键字的每一位取值都不够均匀或均小于散列地址所需的位数**。

##### 0x03 数字分析法

**这种方法适合已知关键字的集合，如果更换了关键字就需要重新构造散列函数**，在已知关键字集合的情况下，对关键字进行分析，分析每一个关键字中的数字在每一位上的出现频率，然后选取其中数字分布较为均匀的几位作为散列地址。

##### 0x04 折叠法

关键字分割成位数相同的几部分，然后取这几部分的叠加值作为散列值。**当关键字中每一位上的分布大致均匀时，可采用折叠法得到散列值**

#### 0x02 冲突处理

散列函数都不可能绝对地避免冲突（Collision），当发生冲突时，一般需要再找一个空的Hash地址来存放这个数据，目前有如下几种常用的方法用来解决冲突（collision resolution）。

##### 0x00 开放定址法

开放定址法（Open addressing）指的是可存放新表项的空闲地址即向它的同义词表项开放，又向它的非同义词表项开放，其递推公式如下：
$$
Addr_i = (\text{Hashfunc}(key)+d_i)\%m
$$
其中m为表长，$d_i$为增量序列，$Addr_i$为计算得出的地址。当确定某一增量序列后，可以采用的处理方法往往是确定的，通常由如下几种方法：

* **线性探测法（Linear probing）**：冲突发生时，顺序查看表中的下一个单元，直到找到一个空闲单元把他放进去，如果遇到表尾，那就从表首地址处继续，所以，在表未满的情况下，总能找到一个空闲单元。
  线性探测法可能使第n个散列地址的同义词存入n+1的位置，然后本该存储n+1位置的元素又要去争抢n+2的位置，以此类推，从而**会造成大的元素在相邻的散列地址上聚集起来（Primary clustering）**，降低了查找效率。如下图：

![](https://bucket.shaoqunliu.cn/image/0208.png)

* **平方探测法（又称二次探测法Quadratic probing）**：就是当发生冲突时，在原hash地址的基础上加上一个任意的二次多项式（arbitrary quadratic polynomial）以获取新的存储地址。这个二次多项式怎么来呢，下面介绍一下这个算法，当给定一个key值时，我们已经通过hash函数计算出了其hash值为H，但是H位置上已经有元素在占了，如果按照线性探测法，那接下来的判定序列为：
  $$
  H+1, H+2,...,H+k
  $$
  如果使用平方探测法，接下来的判定序列即为：
  $$
  H+1^2, H+2^2,...,H+k^2
  $$
  其中$k \leqslant \frac{m}{2}$，且**散列表的长度m必需是一个可表示成4k+3的素数**。
  别看仅仅在线性探测的序列上对增量加了个平方，这却有效地缓解了线性探测中失效后元素的聚集问题（clustering problem）。
  它的缺点在于**不能探测到散列表上的所有单元，但至少能探测到一半的单元**。
  这种方法被用于**Unix文件系统（Unix File System又称Berkeley Fast File System）用于分配新的空闲块**。

* **再散列法（Double hashing）**：此种方法需要使用2个散列函数，当第一个散列函数计算出来的地址值发生冲突时，再由**第二个散列函数计算该关键字的地址增量**。其具体的散列函数形式如下：
  $$
  Addr_i = (\text{Hash}_1(key)+i\times \text{Hash}_2(key))\%m
  $$
  上式中的$i$为冲突发生的次数，初始为0，再散列法中，**最多经过m-1次探测就会遍历表中所有的位置回到$Addr_0$的位置**。

在开放定址的情形下，**不能随便物理删除表中已有元素**，因为删除元素将会截断其他具有相同散列地址元素的查找地址。所以若想删除一个地址，**需要给它做一个删除标记**，在逻辑上删除，这样做的副作用是在执行多次删除后，表面上看起来散列表很满，实际上有许多位置没有利用，因此**需要定期维护散列表**，把带有删除标记的元素物理删除。

同时，即便使用一个良好的hash函数，使用开放定址法进行冲突处理的hash表的查找性能也会随着装填因子的升高而降低。

##### 0x01 拉链法

我们可以把所有同义的关键词全部存储到一个线性链表中，这个线性链表由其散列地址唯一标识，这种处理冲突的方法称为拉链法（Separate chaining）。因为查找、删除、插入操作都在同义词链中进行。所以**拉链法往往适用于经常插入和删除的情况**。如图：

![](https://bucket.shaoqunliu.cn/image/0209.png)

一个设计优良的hash表使用拉链法来解决冲突，每一个bucket应含有0个或1个链表项（entries），有时可能出现2-3个，再多的情况下就很少出现了。